# YouTube Summarizer & Q&A Bot

A Telegram bot skill for [OpenClaw](https://openclaw.ai) that summarizes YouTube videos and answers follow-up questions about them. Built as an internship assignment.

## Features

- **Structured Summaries** â€” ğŸ¥ Title, ğŸ“Œ 5 Key Points, â± Timestamps, ğŸ§  Core Takeaway
- **Follow-up Q&A** â€” Ask questions grounded in the transcript (no hallucinations)
- **Multi-language** â€” Responds in Hindi, Tamil, Kannada, and other Indian languages on request
- **Caching** â€” Transcripts cached locally for 7 days to avoid redundant API calls
- **Error Handling** â€” Friendly messages for invalid URLs, missing captions, private videos, rate limits
- **Bonus Commands** â€” `/summary`, `/deepdive`, `/actionpoints`, `/lang`

## Screenshots

### Video Summary
![Summary](screenshots/summary.png)

### Follow-up Q&A
![Q&A Answer](screenshots/qa-answer.png)

### Not Covered in Video
![Not Covered](screenshots/qa-not-covered.png)

### Hindi Summary
![Hindi](screenshots/hindi.png)

### Error Handling
![Error](screenshots/error.png)

## Architecture

```
User (Telegram)
    â”‚
    â–¼
OpenClaw Gateway â”€â”€â–¶ Reads SKILL.md instructions
    â”‚
    â–¼
Gemini 2.5 Flash (LLM) detects YouTube URL
    â”‚
    â–¼
Runs: python index.py "<video_url>"
    â”‚
    â”œâ”€â”€ extract_video_id.py  â†’  Parses URL into video ID
    â”œâ”€â”€ youtube-transcript-api â†’  Fetches transcript from YouTube
    â”œâ”€â”€ format_transcript.py â†’  Formats into timestamped text
    â”œâ”€â”€ chunk_transcript.py  â†’  Splits long videos into chunks
    â””â”€â”€ cache/               â†’  Saves transcript JSON locally
    â”‚
    â–¼
Transcript text returned to stdout
    â”‚
    â–¼
Gemini reads transcript â†’ Generates summary â†’ Sends to Telegram
    â”‚
    â–¼
Session memory retains transcript context for Q&A follow-ups
```

### How It Works

1. **Trigger**: User sends a YouTube link on Telegram
2. **Skill Activation**: OpenClaw matches the URL against the youtube-summarizer skill description
3. **Transcript Fetch**: The LLM runs `index.py` via shell command, which fetches the transcript using `youtube-transcript-api`
4. **Summary Generation**: The LLM reads the transcript and generates a structured summary following the SKILL.md template
5. **Q&A**: Session memory stores the transcript context, allowing follow-up questions grounded in the video content
6. **Language**: The LLM responds in whatever language the user requests

### Chunking (Long Videos)

Videos over ~30 minutes produce transcripts that exceed comfortable context sizes. The `chunk_transcript.py` module splits the transcript into ~4000-character chunks on newline boundaries. The output becomes a JSON object with all chunks, and the LLM processes them all.

### Language Switching

No translation API is used. The LLM (Gemini 2.5 Flash) natively handles multilingual output. When the user says "Summarize in Hindi" or "Explain in Kannada", the SKILL.md instructions tell the LLM to respond in that language. The preference persists for the session.

## Setup

### Prerequisites

- [OpenClaw](https://openclaw.ai) installed and running locally
- Python 3.10+
- A Telegram bot connected to OpenClaw

### Installation

```powershell
# Navigate to the skill directory
cd C:\Users\harsh\.openclaw\workspace\skills\youtube-summarizer

# Create and activate virtual environment
python -m venv venv
.\venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Verify

```powershell
# Test transcript fetching
python index.py dQw4w9WgXcQ

# Restart OpenClaw gateway to load the skill
# (Ctrl+C the running gateway, then start it again)
openclaw gateway

# Check skill is loaded
openclaw skills info youtube-summarizer
```

Then send a YouTube link to your Telegram bot.

## File Structure

```
youtube-summarizer/
â”œâ”€â”€ SKILL.md                  â† Skill definition (instructions for the LLM)
â”œâ”€â”€ index.py                  â† Main entry point (transcript fetcher + caching)
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extract_video_id.py   â† YouTube URL â†’ video ID parser
â”‚   â”œâ”€â”€ format_transcript.py  â† Raw transcript â†’ timestamped text
â”‚   â””â”€â”€ chunk_transcript.py   â† Splits long transcripts into chunks
â”œâ”€â”€ cache/                    â† Auto-created, stores transcript JSON files
â”œâ”€â”€ screenshots/              â† Demo screenshots for README
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Design Trade-offs

| Decision | Why |
|----------|-----|
| **Python over Node.js** | All Node YouTube transcript packages are broken due to YouTube backend changes. Python's `youtube-transcript-api` is the only reliable option. |
| **No direct LLM API calls** | OpenClaw handles LLM routing. The skill only fetches transcripts; all intelligence comes from Gemini via OpenClaw. |
| **No translation API** | Gemini handles multilingual output natively â€” no need for Google Translate or similar paid APIs. |
| **File-based caching** | Simple JSON files in a `cache/` directory. No database needed for an intern project. TTL is 7 days. |
| **4000-char chunks** | Conservative chunk size that works well within Gemini's context window while leaving room for the summary prompt. |
| **`{baseDir}` in SKILL.md** | OpenClaw convention â€” resolves to the skill folder path at runtime, making the skill portable. |

## Tech Stack

- **Runtime**: Python 3.x
- **Skill System**: OpenClaw (self-hosted AI gateway)
- **Transcript Fetching**: `youtube-transcript-api` v1.2.4
- **LLM**: Google Gemini 2.5 Flash (via OpenClaw)
- **Channel**: Telegram (via OpenClaw's Telegram connector)
- **OS**: Windows

## Limitations

- Requires videos to have captions/subtitles enabled
- YouTube may rate-limit or block requests temporarily
- Video title is inferred from transcript content (not from YouTube metadata)
- Cache is local only â€” not shared across machines
